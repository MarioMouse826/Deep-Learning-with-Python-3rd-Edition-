{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmGCCXhp3ZbbI4i9OiZGAJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioMouse826/Deep-Learning-with-Python-3rd-Edition-/blob/main/NeuralNetworksMathematicsPractice_Chapter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the MNIST dataset in Keras"
      ],
      "metadata": {
        "id": "3uOw2WIQgBtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQCdTIlXfxZ6",
        "outputId": "590e039a-5a65-4b9d-e1a0-04d4c6c38670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-nlp 0.21.1 requires keras-hub==0.21.1, but you have keras-hub 0.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install keras keras-hub --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
      ],
      "metadata": {
        "id": "gVFGqilegih_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def backend(line, cell):\n",
        "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
        "    if current == required:\n",
        "        get_ipython().run_cell(cell)\n",
        "    else:\n",
        "        print(\n",
        "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
        "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
        "        )"
      ],
      "metadata": {
        "id": "qoFoLSJqgkZy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_images and train_labels form the training set, the data that the model will learn from. The model will then be tested on the test set, test_images and test_labels. The images are encoded as NumPy arrays, and the labels are an array of digits, ranging from 0 to 9.\n",
        "\n",
        "# NumPy is a popular Python library for numerical computation. It is rarely used to implement modern ML algorithms due to lacking GPU and autodifferentiation support, but NumPy arrays are often used as a numerical data exchange format for MNIST digits and their labels."
      ],
      "metadata": {
        "id": "7CMifXoiiiMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "BSifmEcdgwlI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdXkMUFvhAqo",
        "outputId": "a51583a1-0b54-40e1-8a6b-9fbf173e5aa4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_QhfoY7hKRt",
        "outputId": "c3bcc77c-682a-4404-f42a-9d830a12606b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNP3SOvwhPS1",
        "outputId": "fb3654b8-a404-4e5f-8a98-e513a8e7b753"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Luy12hOuhfvK",
        "outputId": "bbf0bc5b-1d16-46ce-a23f-d5e7bf14903f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhDMHrAkhiVk",
        "outputId": "ab9a773a-d7ce-4dc3-9aa9-038276b92eaa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Lg5g4khkUo",
        "outputId": "1dacf728-3d49-4956-8285-ed76bb196061"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Network Architecture"
      ],
      "metadata": {
        "id": "qQmYFskiicUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core building block of neural networks is the layer. You can think of a layer as a filter for data: some data goes in, and it comes out in a more useful form. Specifically, layers extract *representations* out of the data fed into them - hopefully the representations are more meaningful for the problem at hand. Most of deep learning consists of chaining together simply layers that will implement a form of progressive *data distillation*. A deep learning model is like a sieve for data processing made out of a succession of increasingly refined data filters - the layers."
      ],
      "metadata": {
        "id": "xud17C7xje0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "model = keras.Sequential(\n",
        "  [\n",
        "      layers.Dense(512, activation=\"relu\"),\n",
        "      layers.Dense(10, activation=\"softmax\"),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "4eYsRr_LhqBX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, our model consists of a sequence of two Dense layers, which are densely (fully connected) neural layers. The second (and last) layer is a 10-way softmax *classification* layer, which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes."
      ],
      "metadata": {
        "id": "QfAq7-9Aj8dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the model ready for training, we need to pick up three more things, as part of the *compilation* step:\n",
        "\n",
        "# A Loss Function - How the model will be able to measure its performance on the training data and thus how it will be able to steer itself in the right direction\n",
        "\n",
        "# An Optimizer - The mechanism through which the model will update itself based on the training data it sees, to improve its performance\n",
        "\n",
        "# Metrics to Monitor during training and testing - Here, we will only care about accuracy (the fraction of the images that were correctly classified)."
      ],
      "metadata": {
        "id": "Y9YX_NOAkQiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Compilation Step"
      ],
      "metadata": {
        "id": "1XHQh7XokvH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "CPmRp0J_h_vZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the image data\n",
        "\n",
        "Before training, we will *preprocess* the data by reshaping it into the shape the model expects and scaling it so that all values are in the [0, 1] interval. Previously, our training images were stored in an array of shape (60000, 28, 28) of type uint8 with values int he [0, 255] interval. We transform it into a float32 array of shape (60000, 28*28) with values between 0 and 1."
      ],
      "metadata": {
        "id": "CZBLPiIvkz9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "XVlhrl9-iY6G"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to train the model, which in Keras is done via a call to the model's fit() method - we *fit* the model to its training data"
      ],
      "metadata": {
        "id": "GVa1tucvluqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG3F3_Iyl04X",
        "outputId": "92e9a113-1eba-4d15-e2ef-8c1faa503ca2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8686 - loss: 0.4600\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9647 - loss: 0.1222\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9800 - loss: 0.0736\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9859 - loss: 0.0507\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9889 - loss: 0.0379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eb7c004c500>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two quantities are displayed during training: the loss of the model over the training data and the accuracy of the model over the training data. We quickly reach an accuracy of 0.989 (98.9%) on the training data. Now that we have a trained model, we can use it to predict class probabilities for *new* digits-images that were not part of the training data, like those from the test set."
      ],
      "metadata": {
        "id": "Gl40DZyomJLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the model to make predictions"
      ],
      "metadata": {
        "id": "Jt0y_D2zmZEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "predictions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyVx80V9mECJ",
        "outputId": "59e31542-7f23-4cae-cd86-02972bcfd1e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.10540474e-07, 4.24888960e-08, 1.31033385e-05, 2.37798289e-04,\n",
              "       1.78984327e-10, 6.96450570e-07, 3.57544896e-11, 9.99728084e-01,\n",
              "       1.16284104e-06, 1.87930054e-05], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each number of index i in that array corresponds to the probability that digit image test_digits[0] belong to class i. The first test digit has the highest probability score (0.99999106, so almost 1) at index 7, so according to our model it must be a 7:"
      ],
      "metadata": {
        "id": "FY43DyMWmwtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0].argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxX6e7j6m_cz",
        "outputId": "d7bea680-4e4b-40c2-eca6-ebc1b38a02df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(7)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0][7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VJpBDnPnJIO",
        "outputId": "bed41366-4184-4ee6-ceb5-cecc547eb80a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.9997281)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[0] #Check that the test label agrees"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruLOujeonNCy",
        "outputId": "fec121c5-de66-4317-9d7d-40e53bd4cf9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(7)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On average how good is our model at classifying such never-before-seen digits? Let us check by computing average accuracy over the entire test set."
      ],
      "metadata": {
        "id": "X3vUf1fzniJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYW9tq5VnSbS",
        "outputId": "e35026c2-1d85-4a11-cd36-96089bbca320"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9758 - loss: 0.0789\n",
            "test_acc: 0.9800000190734863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test set accuracy turns out to be 97.8% - that's almost double the error rate of the training set (at 98.7% accuracy). This gap between training accuracy and test accuracy is an example of *overfitting*. The fact is that the machine learning models tend to perform worse on the test set than on their training data. This should conclude our first example. we just built and trained a very simple neural network to classify handwritten digits in less than 15 lines of Python code."
      ],
      "metadata": {
        "id": "hrEz16rNnmpp"
      }
    }
  ]
}
